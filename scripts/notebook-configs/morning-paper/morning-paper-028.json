{
  "title": "Morning Paper #028: Latent Jailbreak a Benchmark for Evaluating Text Safety and Output Robustness of Large Language Models",
  "sources": [
    "textfile:/Users/adrian/repos/failure-first-embodied-ai/data/papers_cache/top_cited_llm_vlm_vla_security_2026-02-08/028_latent_jailbreak_a_benchmark_for_evaluating_text_safety_and_output_robustness_of_large_language_models.pdf"
  ],
  "studio": [
    {
      "type": "audio"
    }
  ]
}
